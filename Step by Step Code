import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

class HousingPricePredictor:
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None
        
    def load_and_prepare_data(self, data_path=None):
        """Load and prepare housing data"""
        if data_path:
            df = pd.read_csv(data_path)
        else:
            # Use California housing dataset
            from sklearn.datasets import fetch_california_housing
            housing = fetch_california_housing()
            df = pd.DataFrame(housing.data, columns=housing.feature_names)
            df['price'] = housing.target
        
        return df
    
    def preprocess_data(self, df):
        """Comprehensive data preprocessing"""
        # Feature engineering
        df_processed = df.copy()
        
        # Create new features
        df_processed['rooms_per_household'] = df_processed['AveRooms'] * df_processed['AveOccup']
        df_processed['population_density'] = df_processed['Population'] / df_processed['AveOccup']
        df_processed['bedroom_ratio'] = df_processed['AveBedrms'] / df_processed['AveRooms']
        
        # Remove outliers
        def remove_outliers(data, column, factor=1.5):
            Q1 = data[column].quantile(0.25)
            Q3 = data[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - factor * IQR
            upper_bound = Q3 + factor * IQR
            return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]
        
        # Remove outliers from target variable
        df_processed = remove_outliers(df_processed, 'price')
        
        return df_processed
    
    def train_model(self, df):
        """Train the housing price prediction model"""
        # Separate features and target
        X = df.drop('price', axis=1)
        y = df['price']
        
        # Store feature names
        self.feature_names = X.columns.tolist()
        
        # Split the data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Scale features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Hyperparameter tuning
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, 30, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        rf = RandomForestRegressor(random_state=42)
        grid_search = GridSearchCV(
            rf, param_grid, cv=5, 
            scoring='neg_mean_squared_error', 
            n_jobs=-1, verbose=1
        )
        
        # Train model
        grid_search.fit(X_train_scaled, y_train)
        self.model = grid_search.best_estimator_
        
        # Make predictions
        y_pred = self.model.predict(X_test_scaled)
        
        # Calculate metrics
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f"Best parameters: {grid_search.best_params_}")
        print(f"RMSE: {rmse:.4f}")
        print(f"MAE: {mae:.4f}")
        print(f"RÂ² Score: {r2:.4f}")
        
        return {
            'X_test': X_test_scaled,
            'y_test': y_test,
            'y_pred': y_pred,
            'metrics': {'rmse': rmse, 'mae': mae, 'r2': r2}
        }
    
    def predict_price(self, house_features):
        """Predict price for new house"""
        if self.model is None:
            raise ValueError("Model not trained yet!")
        
        # Ensure features are in correct order
        features_df = pd.DataFrame([house_features], columns=self.feature_names)
        features_scaled = self.scaler.transform(features_df)
        
        prediction = self.model.predict(features_scaled)[0]
        return prediction
    
    def get_feature_importance(self):
        """Get feature importance from the trained model"""
        if self.model is None:
            raise ValueError("Model not trained yet!")
        
        importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        return importance_df

# Usage example
predictor = HousingPricePredictor()

# Load and prepare data
df = predictor.load_and_prepare_data()
df_processed = predictor.preprocess_data(df)

# Train model
results = predictor.train_model(df_processed)

# Feature importance
importance = predictor.get_feature_importance()
print("\nTop 5 Most Important Features:")
print(importance.head())

# Example prediction
sample_house = {
    'MedInc': 5.0,
    'HouseAge': 10.0,
    'AveRooms': 6.0,
    'AveBedrms': 1.2,
    'Population': 3000.0,
    'AveOccup': 3.0,
    'Latitude': 34.0,
    'Longitude': -118.0,
    'rooms_per_household': 18.0,
    'population_density': 1000.0,
    'bedroom_ratio': 0
